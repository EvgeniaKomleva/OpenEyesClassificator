{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evgenia/opt/miniconda3/envs/env/lib/python3.7/site-packages/torchvision/transforms/transforms.py:734: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.RandomHorizontalFlip(p=0.2),\n",
    "    transforms.RandomRotation(degrees=(-45, 45)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.7, p=1, interpolation=2, fill=0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4976, 0.4976, 0.4976],\n",
    "                         std=[0.1970, 0.1970, 0.1970]),\n",
    "    ])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4976, 0.4976, 0.4976],\n",
    "                          std=[0.1970, 0.1970, 0.1970])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "DATA_DIR = '/Users/evgenia/OpenEyesClassificator/'\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=os.path.join(DATA_DIR, 'eyes'), transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True,  \n",
    "                          num_workers=0)\n",
    "\n",
    "val_dataset = torchvision.datasets.ImageFolder(root=os.path.join(DATA_DIR, 'eyes'), \n",
    "                                               transform=val_transform)\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        shuffle=True, \n",
    "                        num_workers=0) \n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(root=os.path.join(DATA_DIR, 'eyes'), \n",
    "                                                transform=val_transform)\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=True, \n",
    "                         num_workers=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['closed', 'open'], {'closed': 0, 'open': 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.find_classes(os.path.join(DATA_DIR, 'eyes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eer(labels, scores):\n",
    "    \"\"\"Compute the Equal Error Rate (EER) from the predictions and scores.\n",
    "    Args:\n",
    "        labels (list[int]): values indicating whether the ground truth\n",
    "            value is positive (1) or negative (0).\n",
    "        scores (list[float]): the confidence of the prediction that the\n",
    "            given sample is a positive.\n",
    "    Return:\n",
    "        (float, thresh): the Equal Error Rate and the corresponding threshold\n",
    "    NOTES:\n",
    "       The EER corresponds to the point on the ROC curve that intersects\n",
    "       the line given by the equation 1 = FPR + TPR.\n",
    "       The implementation of the function was taken from here:\n",
    "       https://yangcha.github.io/EER-ROC/\n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores, pos_label=1)\n",
    "    eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    thresh = interp1d(fpr, thresholds)(eer)\n",
    "    return eer, thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, loader, ckpt_path=False):\n",
    "    if ckpt_path:\n",
    "        model.load_state_dict(torch.load(ckpt_path))\n",
    "\n",
    "    val_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    val_labels = []\n",
    "    val_probs = []\n",
    "    model.eval()  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "          \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "            val_labels += labels.cpu().numpy().tolist()\n",
    "            val_probs += probs[:, 1].cpu().numpy().tolist()\n",
    "\n",
    "    eer, _ = compute_eer(val_labels, val_probs)\n",
    "\n",
    "    return val_loss, correct / total, eer\n",
    "\n",
    "def train(model, epoch_num, optimizer, ckpt_save_path):\n",
    "    print(criterion, optimizer)\n",
    "    min_val_eer = np.inf\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        print(epoch)\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        print('_______')\n",
    "        val_loss, val_accuracy, val_eer = eval(model, val_loader)\n",
    "        test_loss, test_accuracy, test_eer = eval(model, test_loader)\n",
    "\n",
    "        print('\\033[1m' + f'Epoch {epoch}:' + '\\033[0m' + f' train loss = {train_loss:.4f}')\n",
    "        print(f'val loss = {val_loss:.4f}, val accuracy = {val_accuracy:.4f}, val eer = {val_eer:.4f}')\n",
    "        print(f'test loss = {test_loss:.4f}, test accuracy = {test_accuracy:.4f}, test eer = {test_eer:.4f}')\n",
    "\n",
    "        if (val_eer < min_val_eer) or (val_eer < .02):\n",
    "            min_val_eer = val_eer\n",
    "            torch.save(model.state_dict(), ckpt_save_path)\n",
    "            print(f'Saving new weights with current val loss = {val_loss:.4f}, val accuracy = {val_accuracy:.4f}, val eer = {val_eer:.4f}, test eer = {test_eer:.4f}')\n",
    "\n",
    "\n",
    "    return eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss() SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.0008\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0.002\n",
      ")\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "model = models.wide_resnet50_2(pretrained=True)\n",
    "model.fc = nn.Linear(2048, 2)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=0.0008, \n",
    "                      momentum=0.9, \n",
    "                      nesterov=True, \n",
    "                      weight_decay=0.002)\n",
    "\n",
    "_ = train(model, 80, optimizer, '/models/wide_resnet50_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "830d2a248d187695c29e6e31f134f4cecf5fb343e84af247fb1c47b8868c8ea8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
